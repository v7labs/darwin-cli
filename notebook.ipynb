{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from darwin.torch.dataset import InstanceSegmentationDataset\n",
    "from darwin.torch.transforms import ConvertPolygonsToInstanceMasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n\n"
    }
   ],
   "source": [
    "root = Path('/Users/andrea/.darwin/datasets/complex')\n",
    "split = Path('/Users/andrea/.darwin/datasets/complex/lists/split/random_train.txt')\n",
    "with open(split, 'r') as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "dataset = InstanceSegmentationDataset(root, split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[19.79, 16.87, 19.79, 14.66, 19.73, 14.66, 19.66, 14.6, 18.54, 14.6, 18.41, 14.66, 18.35, 14.86, 18.31, 15.05, 17.84, 15.05, 17.84, 15.3, 17.65, 15.68, 17.58, 15.87, 17.52, 16.0, 17.46, 16.25, 17.46, 16.38, 17.39, 16.51, 17.39, 18.33, 17.46, 18.46, 17.52, 18.52, 17.52, 18.58, 17.65, 18.65, 19.09, 18.65, 19.22, 18.58, 19.47, 18.33, 19.54, 18.2, 19.6, 17.89, 19.66, 17.7, 19.73, 17.38, 19.73, 17.12], [23.4, 20.73, 23.38, 20.66, 23.06, 19.77, 22.8, 19.33, 22.49, 18.95, 22.11, 18.63, 21.92, 18.44, 21.54, 18.19, 21.15, 18.0, 20.96, 17.93, 20.79, 17.9, 20.72, 17.93, 20.53, 18.12, 20.28, 18.31, 20.09, 18.44, 19.9, 18.69, 19.58, 19.01, 19.45, 19.26, 19.2, 19.58, 19.01, 19.96, 18.95, 20.28, 18.82, 20.66, 18.76, 20.91, 18.69, 21.42, 18.69, 21.99, 18.66, 22.27, 18.69, 22.55, 18.69, 22.8, 18.76, 23.19, 18.82, 23.44, 18.95, 23.82, 19.01, 24.07, 19.2, 24.39, 19.39, 24.64, 19.9, 25.15, 19.96, 25.34, 20.28, 25.66, 20.41, 25.85, 20.6, 25.98, 20.98, 26.17, 21.14, 26.22, 21.41, 26.04, 21.6, 25.79, 21.79, 25.6, 21.98, 25.28, 22.11, 25.09, 22.3, 24.64, 22.42, 24.45, 22.55, 24.07, 22.61, 23.82, 22.74, 23.5, 22.87, 23.12, 22.93, 22.99, 23.06, 22.36, 23.19, 21.6, 23.31, 21.22], [26.31, 24.85, 26.31, 20.84, 26.24, 20.33, 26.24, 20.01, 26.18, 19.8, 26.18, 17.03, 26.12, 16.4, 25.8, 15.44, 25.48, 14.81, 25.36, 14.62, 25.23, 14.37, 25.04, 14.17, 24.78, 13.86, 24.4, 13.6, 23.83, 13.41, 23.71, 13.35, 19.38, 13.35, 19.25, 13.41, 19.0, 13.41, 18.93, 13.48, 18.81, 13.48, 18.68, 13.54, 18.49, 13.6, 18.43, 13.67, 18.24, 13.79, 18.11, 13.92, 17.73, 14.17, 17.54, 14.37, 17.22, 14.56, 17.09, 14.68, 17.09, 14.75, 16.97, 15.0, 16.84, 15.13, 16.84, 15.25, 16.78, 15.32, 16.78, 16.27, 16.71, 16.46, 16.59, 16.59, 16.33, 17.09, 16.14, 17.66, 15.95, 18.11, 15.89, 18.43, 15.76, 19.19, 15.76, 19.63, 15.7, 20.14, 15.7, 24.78, 15.76, 25.36, 15.76, 25.61, 15.89, 26.18, 16.02, 26.56, 16.21, 26.94, 16.4, 27.39, 16.52, 27.7, 16.78, 28.02, 17.03, 28.4, 17.35, 28.72, 17.54, 28.85, 17.98, 29.1, 18.36, 29.35, 18.68, 29.54, 19.0, 29.67, 19.5, 29.8, 19.89, 29.92, 20.14, 29.92, 20.52, 29.99, 23.2, 29.99, 23.52, 29.92, 23.77, 29.86, 24.09, 29.67, 24.34, 29.48, 24.78, 29.04, 25.04, 28.72, 25.23, 28.4, 25.48, 27.96, 25.67, 27.64, 25.93, 27.07, 25.99, 26.88, 26.05, 26.37, 26.12, 25.99, 26.18, 25.55, 26.24, 25.23]], [[33.06, 13.52, 41.18, 18.15, 46.57, 7.3, 38.64, 4.19, 31.15, 5.77]]]\n"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "jsonfile = Path('/Users/andrea/Downloads/11.json')\n",
    "segmentations = []\n",
    "with open(jsonfile, 'r') as f:\n",
    "    a = json.load(f)\n",
    "    for b in a['annotations']:\n",
    "        if 'complex_polygon' in b:\n",
    "            path = b['complex_polygon']['path']\n",
    "            path = [[[q['x'], q['y']] for q in p] for p in path]\n",
    "        else:\n",
    "            path = b['polygon']['path']\n",
    "            path = [[[p['x'], p['y']] for p in path]]\n",
    "        segmentations.append([[c for q in p for c in q] for p in path])\n",
    "print(segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1920x1080 at 0x12AE185F8>,\n {'boxes': tensor([[ 799.8100,  289.5000,  974.3300,  564.4800],\n          [1143.8900,  162.3400, 1355.1500,  379.9700]]),\n  'labels': tensor([1, 1]),\n  'masks': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           ...,\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0]],\n  \n          [[0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           ...,\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8),\n  'image_id': tensor([0]),\n  'area': tensor([53945.0625, 37230.7422]),\n  'iscrowd': tensor([0, 0])})"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=1920x1080 at 0x12AF43F28>",
      "image/png": "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\n"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transforms.ToPILImage()(dataset[0][1]['masks'][0] * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=L size=50x50 at 0x130933358>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAAAgElEQVR4nO2RwQ7AIAhDgfD/v9wdNHMDgWWnZeFdVLDURqKm+RwMtiWMRiKCPeO6PHFB4UDEZDQgxtnbIr4RvmiiuGuwDCKp2gKDiFMrce/Ks28uYDX8j02XMq1Do1nxJJ+lRPbTskE2y7jLWUDZVpE56YsstsBuU0rq32+a5gccOFMbJpIidtsAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from upolygon import draw_polygon\n",
    "\n",
    "masks = []\n",
    "for contour in segmentations:\n",
    "    mask = torch.zeros((50, 50)).numpy().astype(np.uint8)\n",
    "    mask_t = torch.from_numpy(np.asarray(draw_polygon(mask, contour, 255)))\n",
    "    im = transforms.ToPILImage()(mask_t)\n",
    "    masks.append(mask_t)\n",
    "    break\n",
    "# transforms.ToPILImage()(torch.stack(masks))\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitpy37conda235875e5107c48f18fa1920d75f6f09b",
   "display_name": "Python 3.7.3 64-bit ('py37': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}